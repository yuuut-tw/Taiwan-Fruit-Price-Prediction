{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練集&測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    test_samples = int(df.shape[0]*0.2)\n",
    "    \n",
    "    # 訓練集\n",
    "    train_data = df.iloc[:-test_samples, :]\n",
    "    train_set = train_data.values   # 取得train_set(array)\n",
    " \n",
    "    \n",
    "    # 測試集\n",
    "    test_data = df.iloc[-test_samples: , :]\n",
    "    test_set = test_data.values             # 取得test_set(array)\n",
    "       \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_normalization(input_set):\n",
    "    \n",
    "    # 訓練集(scaler)\n",
    "    sc = StandardScaler()\n",
    "    input_set_sc = sc.fit_transform(input_set[:, :])\n",
    "\n",
    "    sc_target = StandardScaler()\n",
    "    sc_target.fit_transform(input_set[:, 0:1])\n",
    "    \n",
    "    return input_set_sc, sc_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 創造X、Y資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_Xy(input_set_sc, n_future, n_past):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(n_past, len(input_set_sc)-n_future+1): # 扣掉最後預測天數已符合y_test的length \n",
    "        X.append(input_set_sc[i-n_past:i, 1:])       # 利用前30天資料來預測後7天價格，特徵值排除banana價格本身\n",
    "        y.append(input_set_sc[i:i+n_future, 0])      # 後7天價格\n",
    "\n",
    "    X, y = np.array(X), np.array(y) \n",
    "    \n",
    "    print(\"X_test's shape: {}\".format(X.shape))\n",
    "    print(\"y_test's shape: {}\".format(y.shape))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model biluder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creator(n_steps, n_feature):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1st layer \n",
    "    # input_shape => n_step, n_feature \n",
    "\n",
    "\n",
    "    model.add(LSTM(units=64, activation=\"relu\", input_shape=(n_steps, n_features), return_sequences=True)) \n",
    "\n",
    "    model.add(LSTM(units=32, activation=\"relu\", return_sequences=False))          \n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(y_train.shape[1]))          \n",
    "\n",
    "    model.summary() \n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trained(model, X_train, y_train, epoch, batch_size):\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    \n",
    "    # 提升訓練效率\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
    "    rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
    "    mcp = ModelCheckpoint(filepath='weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epoch, \n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[es, rlr, mcp], \n",
    "                        validation_split=0.1, \n",
    "                        verbose=1)\n",
    "    # 視覺化\n",
    "    plt.plot(history.history['loss'], label='Training loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
